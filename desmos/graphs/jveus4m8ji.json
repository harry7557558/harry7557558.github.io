{"hash":"jveus4m8ji","parent_hash":"mb6uwzcpdi","thumbUrl":"https://saved-work.desmos.com/calc_thumbs/production/jveus4m8ji.png","stateUrl":"https://saved-work.desmos.com/calc-states/production/jveus4m8ji","title":"Tanh Activation Loss Function","access":"link","created":"Wed, 20 Apr 2022 22:10:51 GMT","state":{"version":9,"randomSeed":"5545794f212915577a0a33db3c19bf9f","graph":{"viewport":{"xmin":-1.6354039006924497,"ymin":-1.3846228760094166,"xmax":1.8119889188609228,"ymax":1.491468399784057}},"expressions":{"list":[{"type":"text","id":"25","text":"Trying to find a loss function for the tanh activation function on a single layer neural network"},{"type":"text","id":"23","text":"Training data"},{"type":"expression","id":"31","color":"#c74440","latex":"N=20","slider":{"hardMin":true,"hardMax":true,"min":"1","max":"100","step":"1"}},{"type":"expression","id":"32","color":"#2d70b3","latex":"X=\\frac{\\left[-N...N-1\\right]+0.5}{N}"},{"type":"expression","id":"7","color":"#2d70b3","latex":"Y=\\tanh\\left(20\\left(X^{2}-\\sin\\left(2X\\right)+0.2\\right)\\right)"},{"type":"expression","id":"43","color":"#000000","latex":"\\left(X,Y\\right)","dragMode":"NONE","pointSize":"6"},{"type":"text","id":"60","text":"Model"},{"type":"expression","id":"6","color":"#c74440","latex":"F_{0}\\left(w_{0},w_{1},w_{2},w_{3},x\\right)=w_{0}x+w_{1}\\cos\\left(2x\\right)+w_{2}\\cos\\left(4x\\right)+w_{3}\\cos\\left(6x\\right)"},{"type":"expression","id":"44","color":"#6042a6","latex":"F\\left(w_{0},w_{1},w_{2},w_{3},x\\right)=\\tanh\\left(F_{0}\\left(w_{0},w_{1},w_{2},w_{3},x\\right)\\right)"},{"type":"folder","id":"76","title":"Regression without activation, bad","hidden":true,"collapsed":true},{"type":"expression","id":"77","folderId":"76","color":"#000000","latex":"L_{reg}\\left(w_{0},w_{1},w_{2},w_{3}\\right)=\\operatorname{mean}\\left(\\left(F_{0}\\left(w_{0},w_{1},w_{2},w_{3},X\\right)-Y\\right)^{2}\\right)"},{"type":"expression","id":"78","folderId":"76","color":"#c74440","latex":"L_{reg}\\left(w_{reg0},w_{reg1},w_{reg2},w_{reg3}\\right)\\sim0","residualVariable":"e_{reg}","regressionParameters":{"w_{reg0}":-1.1567499953544575,"w_{reg1}":0.3789935455879949,"w_{reg2}":-0.31755726578458177,"w_{reg3}":0.5536288227311695}},{"type":"expression","id":"79","folderId":"76","color":"#fa7e19","latex":"F_{0}\\left(w_{reg0},w_{reg1},w_{reg2},w_{reg3},x\\right)"},{"type":"folder","id":"48","title":"Mean squared error, difficult to train"},{"type":"expression","id":"1","folderId":"48","color":"#c74440","latex":"L_{mse}\\left(w_{0},w_{1},w_{2},w_{3}\\right)=\\operatorname{mean}\\left(\\left(\\tanh\\left(F_{0}\\left(w_{0},w_{1},w_{2},w_{3},X\\right)\\right)-Y\\right)^{2}\\right)"},{"type":"expression","id":"49","folderId":"48","color":"#388c46","latex":"L_{mse}\\left(w_{mse0},w_{mse1},w_{mse2},w_{mse3}\\right)\\sim0","residualVariable":"e_{mse}","regressionParameters":{"w_{mse0}":-172.1565644164795,"w_{mse1}":25.28449033010118,"w_{mse2}":-101.44579002726931,"w_{mse3}":116.7337741630849}},{"type":"expression","id":"45","folderId":"48","color":"#388c46","latex":"F\\left(w_{mse0},w_{mse1},w_{mse2},w_{mse3},x\\right)"},{"type":"expression","id":"64","folderId":"48","color":"#000000","latex":"g_{mse}=\\left[\\frac{d}{dw_{mse0}}L_{mse}\\left(w_{mse0},w_{mse1},w_{mse2},w_{mse3}\\right),\\frac{d}{dw_{mse1}}L_{mse}\\left(w_{mse0},w_{mse1},w_{mse2},w_{mse3}\\right),\\frac{d}{dw_{mse2}}L_{mse}\\left(w_{mse0},w_{mse1},w_{mse2},w_{mse3}\\right),\\frac{d}{dw_{mse3}}L_{mse}\\left(w_{mse0},w_{mse1},w_{mse2},w_{mse3}\\right)\\right]"},{"type":"expression","id":"68","folderId":"48","color":"#6042a6","latex":"\\sqrt{\\operatorname{total}\\left(g_{mse}^{2}\\right)}"},{"type":"expression","id":"66","folderId":"48","color":"#2d70b3","latex":"\\log\\left(L_{mse}\\left(w_{mse0}+x,w_{mse1},w_{mse2},w_{mse3}\\right)\\right)"},{"type":"text","id":"85","folderId":"48","text":"Returned from `scipy.optimize.minimize(method='CG')` with analytical gradient, 0.22secs"},{"type":"expression","id":"83","folderId":"48","color":"#c74440","latex":"L_{mse}\\left(-363.3233727,55.76069111,-215.36267552,245.66609157\\right)"},{"type":"folder","id":"51","title":"Loss function from https://stats.stackexchange.com/a/12767, suffers from floating point precision issues","hidden":true,"collapsed":true},{"type":"expression","id":"9","folderId":"51","color":"#6042a6","latex":"L_{tanh}\\left(w_{0},w_{1},w_{2},w_{3}\\right)=-\\operatorname{mean}\\left(\\left(\\left(1-Y\\right)\\ln\\left(1-\\tanh\\left(F_{0}\\left(w_{0},w_{1},w_{2},w_{3},X\\right)\\right)\\right)+\\left(1+Y\\right)\\ln\\left(1+\\tanh\\left(F_{0}\\left(w_{0},w_{1},w_{2},w_{3},X\\right)\\right)\\right)\\right)\\right)"},{"type":"expression","id":"50","folderId":"51","color":"#6042a6","latex":"L_{tanh}\\left(w_{tanh0},w_{tanh1},w_{tanh2},w_{tanh3}\\right)\\sim-100","residualVariable":"e_{tanh}","regressionParameters":{"w_{tanh0}":-9.762993212923767,"w_{tanh1}":2.2276353717214143,"w_{tanh2}":-6.398317952813263,"w_{tanh3}":6.304871619341438}},{"type":"expression","id":"53","folderId":"51","color":"#c74440","latex":"L_{tanh}\\left(w_{tanh0}+x,w_{tanh1},w_{tanh2},w_{tanh3}\\right)"},{"type":"expression","id":"54","folderId":"51","color":"#c74440","latex":"F\\left(w_{tanh0},w_{tanh1},w_{tanh2},w_{tanh3},x\\right)"},{"type":"folder","id":"55","title":"Extension of an idea I originally thought of when Y[i] is either -1 or 1. The function is always positive and its minimum is theoretically identical to the above"},{"type":"expression","id":"15","folderId":"55","color":"#6042a6","latex":"L_{lnp}\\left(w_{0},w_{1},w_{2},w_{3}\\right)=\\operatorname{mean}\\left(\\left(\\left(1-Y\\right)\\ln\\left(1+e^{2F_{0}\\left(w_{0},w_{1},w_{2},w_{3},X\\right)}\\right)+\\left(1+Y\\right)\\ln\\left(1+e^{-2F_{0}\\left(w_{0},w_{1},w_{2},w_{3},X\\right)}\\right)\\right)^{2}\\right)"},{"type":"expression","id":"56","folderId":"55","color":"#388c46","latex":"L_{lnp}\\left(w_{lnp0},w_{lnp1},w_{lnp2},w_{lnp3}\\right)\\sim0","residualVariable":"e_{lnp}","regressionParameters":{"w_{lnp0}":-26.22291239416036,"w_{lnp1}":3.848765320669438,"w_{lnp2}":-15.817778566623227,"w_{lnp3}":17.396840759607304}},{"type":"expression","id":"58","folderId":"55","color":"#6042a6","latex":"F\\left(w_{lnp0},w_{lnp1},w_{lnp2},w_{lnp3},x\\right)"},{"type":"expression","id":"69","folderId":"55","color":"#000000","latex":"g_{lnp}=\\left[\\frac{d}{dw_{lnp0}}L_{lnp}\\left(w_{lnp0},w_{lnp1},w_{lnp2},w_{lnp3}\\right),\\frac{d}{dw_{lnp1}}L_{lnp}\\left(w_{lnp0},w_{lnp1},w_{lnp2},w_{lnp3}\\right),\\frac{d}{dw_{lnp2}}L_{lnp}\\left(w_{lnp0},w_{lnp1},w_{lnp2},w_{lnp3}\\right),\\frac{d}{dw_{lnp3}}L_{lnp}\\left(w_{lnp0},w_{lnp1},w_{lnp2},w_{lnp3}\\right)\\right]"},{"type":"expression","id":"70","folderId":"55","color":"#c74440","latex":"\\sqrt{\\operatorname{total}\\left(g_{lnp}^{2}\\right)}"},{"type":"expression","id":"57","folderId":"55","color":"#6042a6","latex":"L_{lnp}\\left(w_{lnp0}+x,w_{lnp1},w_{lnp2},w_{lnp3}\\right)"}]}}}